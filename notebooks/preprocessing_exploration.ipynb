{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb6b57e-bdd3-4402-8536-8fe7cd919949",
   "metadata": {},
   "source": [
    "# Explanatory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa997e6-734f-49ab-ba36-1bfd1134c5b1",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb99539-9b58-4ffd-bf70-dc1e0904d77e",
   "metadata": {},
   "source": [
    "Welcome to the Explanatory Data Analysis (EDA) notebook for the Tweet Classification Challenge! In this notebook, we will explore and understand the data that will be used for our tweet classification challenge. EDA is a crucial first step in any data science project, as it allows us to gain valuable insights into our dataset, identify patterns, and make informed decisions about how to approach our classification task effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03b7f9-385e-4add-b2f9-b0f186b23e92",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "&emsp;&ensp;&ensp;[Introduction](#introduction)<br style=\"margin-bottom:0.5em;\">\n",
    "&emsp;&emsp;[1 - Preprocessing](#preprocess)<br style=\"margin-bottom:0.1em;\">\n",
    "&emsp;&emsp;&emsp;&emsp;[1.1 - Preprocessing](#preprocessing-child)<br style=\"margin-bottom:0.1em;\">\n",
    "&emsp;&emsp;&emsp;&emsp;[1.2 - Drop NaN and duplicates](#drop-nan-dup)<br style=\"margin-bottom:0.5em;\">\n",
    "&emsp;&emsp;[2 - Word Analysis](#word-analysis)<br style=\"margin-bottom:0.1em;\">\n",
    "&emsp;&emsp;&emsp;&emsp;[2.1 - Tags](#tags)<br style=\"margin-bottom:0.1em;\">\n",
    "&emsp;&emsp;&emsp;&emsp;[2.2 - Hashtags](#hashtags)<br style=\"margin-bottom:0.1em;\">\n",
    "&emsp;&emsp;&emsp;&emsp;[2.3 - Emojis](#emojis)<br style=\"margin-bottom:0.1em;\">\n",
    "&emsp;&emsp;&emsp;&emsp;[2.4 - Endings](#endings)<br style=\"margin-bottom:0.5em;\">\n",
    "&emsp;&ensp;&ensp;[Summary](#summary)<br style=\"margin-bottom:0.1em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3288402-97ef-4992-b2b8-d1a5bcfe18cf",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558f51e6-070f-4041-bc30-f45773602cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/thainamhoang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thainamhoang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/thainamhoang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/thainamhoang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from preprocessing import Preprocessing, EMOJI_GLOVE\n",
    "from utility.paths import DataPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52287398-8b75-46bf-a187-83238d759763",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9c6fb-e22f-4dc2-993e-3938f09bb153",
   "metadata": {},
   "source": [
    "### 1.1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b80732c-eeb3-43ef-95d7-067d44a4835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vinco tresorpack 6 ( difficulty 10 of 10 objec...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glad i dot have taks tomorrow ! ! #thankful #s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-3 vs celtics in the regular season = were fu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; i could actually kill that girl i'm so ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; i find that very hard to ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  vinco tresorpack 6 ( difficulty 10 of 10 objec...    0.0\n",
       "1  glad i dot have taks tomorrow ! ! #thankful #s...    0.0\n",
       "2  1-3 vs celtics in the regular season = were fu...    0.0\n",
       "3  <user> i could actually kill that girl i'm so ...    0.0\n",
       "4  <user> <user> <user> i find that very hard to ...    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the full dataset into Preprocessing class\n",
    "train_prep = Preprocessing([DataPath.TRAIN_NEG_FULL, DataPath.TRAIN_POS_FULL])\n",
    "\n",
    "# Retrieve the df\n",
    "train_df = train_prep.__get__()\n",
    "\n",
    "# Peak the first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61abfcf-04d7-4942-ab1d-e6eb2fda8a93",
   "metadata": {},
   "source": [
    "*Note: Inside `Preprocessing` class, we convert label `-1` to `0`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b26d1d1-b1a9-47b6-9d77-03ba01941866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ids                                               text\n",
       "0   1  sea doo pro sea scooter ( sports with the port...\n",
       "1   2  <user> shucks well i work all week so now i ca...\n",
       "2   3            i cant stay away from bug thats my baby\n",
       "3   4  <user> no ma'am ! ! ! lol im perfectly fine an...\n",
       "4   5  whenever i fall asleep watching the tv , i alw..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We do the same for test data\n",
    "test_prep = Preprocessing([DataPath.TEST], is_test=True)\n",
    "test_df = test_prep.__get__()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c915676-9bc8-48e5-a7d0-558774af83fc",
   "metadata": {},
   "source": [
    "### 1.2. Drop NaN and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95d85b7-8801-4f18-8925-08058aaa8433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Expand to negative and positive training by label\n",
    "train_neg = train_df[train_df[\"label\"] == 0.0]\n",
    "train_pos = train_df[train_df[\"label\"] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7131c5-0f47-4bce-a0d1-8e8cd074bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN state in negative label: False\n",
      "NaN state in positive label: False\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN\n",
    "print(f\"NaN state in negative label: {train_neg.isna().any().any()}\")\n",
    "print(f\"NaN state in positive label: {train_pos.isna().any().any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85650e24-ee7d-44c9-a9d2-b4f95428c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative label shape: (1250000, 2)\n",
      "Positive label shape: (1250000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape\n",
    "shape_neg = train_neg.shape\n",
    "shape_pos = train_pos.shape\n",
    "\n",
    "print(f\"Negative label shape: {shape_neg}\")\n",
    "print(f\"Positive label shape: {shape_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e08f6d-6ee1-47e6-9f98-8f4939f1c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative label shape after dropping duplicates: (1142838, 2)\n",
      "Positive label shape after dropping duplicates: (1127644, 2)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate in `text` column\n",
    "train_neg = train_neg.drop_duplicates(subset=[\"text\"])\n",
    "train_pos = train_pos.drop_duplicates(subset=[\"text\"])\n",
    "\n",
    "# Check the shape again\n",
    "print(f\"Negative label shape after dropping duplicates: {train_neg.shape}\")\n",
    "print(f\"Positive label shape after dropping duplicates: {train_pos.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c03ada-2918-40df-98af-d771d602df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate percentage for negative label: 8.57%\n",
      "Duplicate percentage for positive label: 9.79%\n"
     ]
    }
   ],
   "source": [
    "# Check the rate of duplication\n",
    "print(f\"Duplicate percentage for negative label: {100 * (1 - train_neg.shape[0] / shape_neg[0]):.2f}%\")\n",
    "print(f\"Duplicate percentage for positive label: {100 * (1 - train_pos.shape[0] / shape_pos[0]):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f75fa2-827e-495d-9dfc-a54fa6594d98",
   "metadata": {},
   "source": [
    "## 2. Word analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faada446-95e4-4281-9cd7-80d2bfe41c97",
   "metadata": {},
   "source": [
    "### 2.1. Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a20a22b-45a7-499e-9096-83c5ce498054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<user>', 1605595),\n",
       " ('<url>', 526862),\n",
       " ('<>', 34),\n",
       " ('<b>', 27),\n",
       " ('<p>', 16),\n",
       " ('<i>', 10),\n",
       " ('<br>', 7),\n",
       " ('<strong>', 6),\n",
       " ('<syrian>', 6),\n",
       " ('<3>', 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all tags by using regex to find `<` and `>` boundings in `text` column of training data\n",
    "all_tags = [tag for tags in train_df[\"text\"].str.findall(\"<[\\w]*>\").values for tag in tags]\n",
    "\n",
    "# Count the occurence\n",
    "count_tags = Counter(all_tags)\n",
    "\n",
    "# View top 10 tags occurence\n",
    "count_tags.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8be85a-e805-40c9-9132-8d1bb7ebb1ec",
   "metadata": {},
   "source": [
    "### 2.2. Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f918615-9cf7-4ad7-a020-5e88811974af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag counts: 114061\n"
     ]
    }
   ],
   "source": [
    "# Find all hashtags by using regex in `text` column of training data\n",
    "all_hashtags = [hashtag for hashtags in train_df[\"text\"].str.findall(\"(#\\w+)\").values for hashtag in hashtags]\n",
    "print(f\"Hashtag counts: {len(set(all_hashtags))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf58c0-6a50-4859-8bf6-79c71c3a11b8",
   "metadata": {},
   "source": [
    "### 2.3. Emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1fd61-dbc7-408f-b05e-e0403cbc551b",
   "metadata": {},
   "source": [
    "Inside `preprocessing.py` there is `EMOJI_GLOVE` which contains emoticons from [this wikipedia link](https://en.wikipedia.org/wiki/List_of_emoticons), retrieved on November 15, 2023.\n",
    "\n",
    "For every text line, we check for the matching parentheses. If it does not match, we then reconstruct the emoji out of it by simply adding `:` before the parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f57a5a-daac-4483-a7b9-5bcce9fc8aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the total emojis\n",
    "count_emojis = sum(len(value) for value in EMOJI_GLOVE.values())\n",
    "count_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d78b8-8b21-4d65-8e7a-c9ea29ec0c1a",
   "metadata": {},
   "source": [
    "### 2.4. Endings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd9de2-956b-4623-b05e-30530e82d16d",
   "metadata": {},
   "source": [
    "We notice that, in some certains row they contain the ending similar to `...` or `... <url>`. We will remove these when preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d9747b-6c8b-4aed-93a3-40261265490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52446 rows end with ellipsis\n"
     ]
    }
   ],
   "source": [
    "# Ellipsis count\n",
    "ellipsis_count = train_df[\"text\"].str.findall(r\"\\...$\").apply(len).values.sum()\n",
    "print(f\"{ellipsis_count} rows end with ellipsis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95fa3276-09e2-4c94-9217-4f70fd55bac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328225 rows end with ellipsis and `<url>`\n"
     ]
    }
   ],
   "source": [
    "# Ellipsis with `<url>` count\n",
    "ellipsis_url_count = train_df[\"text\"].str.findall(r\"\\... <url>$\").apply(len).values.sum()\n",
    "print(f\"{ellipsis_url_count} rows end with ellipsis and `<url>`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9561d8f-3f10-4798-80a5-dc8c79584ca3",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18efb7-551a-4f4d-9a18-45c2c5dd0b0d",
   "metadata": {},
   "source": [
    "In summary, the exploratory data analysis performed on the dataset provided insightful trends and patterns through preprocessing and word analysis. The preprocessing stage ensured data integrity, while the subsequent analysis of tags, hashtags, and emojis revealed core themes, trending topics, and the underlying sentiment within the textual data. The exploration of sentence endings further informed on the communicative effectiveness of the dataset. Collectively, these findings offer a comprehensive understanding of the textual characteristics, serving as a valuable asset for refining approach strategies and preprocessing steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
